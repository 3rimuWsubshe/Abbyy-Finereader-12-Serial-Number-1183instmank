# Vision and Roadmap

## Vision

Our vision is to transform Llama-github into a cornerstone module for AI-driven development solutions. By seamlessly integrating with GitHub, Llama-github will empower Large Language Models (LLMs) to autonomously resolve complex coding tasks. This involves efficiently retrieving relevant code snippets, issues, and repository information, and transforming them into valuable knowledge contexts that enhance the capabilities of LLM Chatbots, AI Agents, and Auto-dev Agents.

### Future Vision: Llama-github in Automated AI-Driven Development

The future vision for Llama-github is to be an integral part of an automated AI-driven development solution. This involves:

- **Efficient Coding Knowledge Retrieval**: Leveraging advanced question analysis and contextual answer generation.
- **Repository Pool Caching**: Enhancing retrieval efficiency through asynchronous processing and flexible GitHub API integration.
- **Contextual Answer Generation**: Utilizing advanced language models to generate comprehensive and contextually relevant answers.

![Vision Architecture](./docs/vision.drawio.svg)

## Roadmap

Our roadmap outlines the key phases and tasks needed to achieve our vision. Each phase builds upon the previous one, ensuring a structured and methodical approach to development.

### Phase 1: In-depth Analysis of a Single Repository
- **Task 1.1**: Initial Repository Content Analysis
- **Task 1.2**: Integrate Advanced Algorithms for In-depth Analysis
- **Task 1.3**: Optimize Retrieval Results

### Phase 2: Predefined Repositories Feature
- **Task 2.1**: Implement User-defined Repository Feature
- **Task 2.2**: Optimize Loading and Analysis of Predefined Repositories
- **Task 2.3**: Enhance Retrieval Speed and Accuracy

### Phase 3: Integration with Vector Database for Persistent Caching
- **Task 3.1**: Integrate Vector Database
- **Task 3.2**: Implement Persistent Caching
- **Task 3.3**: Enhance Large-scale Production Deployment Capability

### Additional Features
- **Add User-defined Retrieval Strategy Feature**
- **Implement Multi-language Support (e.g., Chinese support based on QWen2 model)**
- **Integrate More LLM Providers**

For a detailed view of our project roadmap, please visit our [Project Roadmap](https://github.com/users/JetXu-LLM/projects/2).